{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Operations on Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation with mean: 31.666666666666668\n",
      "Aggregation with multiple functions:\n",
      " mean    31.666667\n",
      "min     10.000000\n",
      "max     60.000000\n",
      "dtype: float64\n",
      "All values are truthy: True\n",
      "At least one value is truthy: True\n",
      "Autocorrelation: 0.7433046224826585\n",
      "Pearson correlation with s2: 0.9254821475438165\n",
      "Covariance with s2: 370.0\n",
      "Maximum value: 60\n",
      "Minimum value: 10\n",
      "Mean value: 31.666666666666668\n",
      "Median value: 30.0\n",
      "Product of values: 240000000\n",
      "50% Quantile: 30.0\n",
      "Quantiles: \n",
      " 0.1    10.0\n",
      "0.5    30.0\n",
      "0.9    55.0\n",
      "dtype: float64\n",
      "Standard error of mean: 8.724168218868268\n",
      "Standard deviation: 21.36976056643281\n",
      "Variance: 456.6666666666667\n",
      "Skewness: 0.23226763043061902\n",
      "Kurtosis: -2.149821514198946\n",
      "Count of unique items: 5\n",
      "Count of non-missing items: 6\n",
      "Size of Series: 6\n",
      "All values are unique: False\n",
      "Values are monotonic increasing: False\n",
      "Values are monotonic decreasing: False\n"
     ]
    }
   ],
   "source": [
    "# Example Series\n",
    "s = pd.Series([10, 20, 10, 40, 50, 60])\n",
    "\n",
    "# 1. Aggregation (single function returns scalar, list of functions returns Series)\n",
    "print(\"Aggregation with mean:\", s.agg('mean'))\n",
    "print(\"Aggregation with multiple functions:\\n\", s.agg(['mean', 'min', 'max']))\n",
    "\n",
    "# 2. All: Returns True if every value is truthy\n",
    "print(\"All values are truthy:\", s.all())\n",
    "\n",
    "# 3. Any: Returns True if at least one value is truthy\n",
    "print(\"At least one value is truthy:\", s.any())\n",
    "\n",
    "# 4. Autocorrelation with lag=1\n",
    "print(\"Autocorrelation:\", s.autocorr(lag=1))\n",
    "\n",
    "# 5. Correlation with another Series\n",
    "s2 = pd.Series([10, 20, 30, 40, 50, 60])\n",
    "print(\"Pearson correlation with s2:\", s.corr(s2))\n",
    "\n",
    "# 6. Covariance with another Series\n",
    "print(\"Covariance with s2:\", s.cov(s2))\n",
    "\n",
    "# 7. Max: Returns maximum value\n",
    "print(\"Maximum value:\", s.max())\n",
    "\n",
    "# 8. Min: Returns minimum value\n",
    "print(\"Minimum value:\", s.min())\n",
    "\n",
    "# 9. Mean: Returns mean value\n",
    "print(\"Mean value:\", s.mean())\n",
    "\n",
    "# 10. Median: Returns median value\n",
    "print(\"Median value:\", s.median())\n",
    "\n",
    "# 11. Product: Returns product of values\n",
    "print(\"Product of values:\", s.prod())\n",
    "\n",
    "# 12. Quantile: Returns specified quantile\n",
    "print(\"50% Quantile:\", s.quantile(q=0.5))\n",
    "print(\"Quantiles: \\n\", s.quantile(q=[.1 , .5, .9])) # returns a series \n",
    "\n",
    "# 13. Standard Error of Mean (SEM)\n",
    "print(\"Standard error of mean:\", s.sem())\n",
    "\n",
    "# 14. Standard Deviation\n",
    "print(\"Standard deviation:\", s.std())\n",
    "\n",
    "# 15. Variance\n",
    "print(\"Variance:\", s.var())\n",
    "\n",
    "# 16. Skewness\n",
    "print(\"Skewness:\", s.skew())\n",
    "\n",
    "# 17. Kurtosis\n",
    "print(\"Kurtosis:\", s.kurtosis())\n",
    "\n",
    "# 18. Count of unique items\n",
    "print(\"Count of unique items:\", s.nunique())\n",
    "\n",
    "# 19. Count of non-missing items\n",
    "print(\"Count of non-missing items:\", s.count())\n",
    "\n",
    "# 20. Size: Number of items in Series\n",
    "print(\"Size of Series:\", s.size)\n",
    "\n",
    "# 21. Is Unique: Check if all values are unique\n",
    "print(\"All values are unique:\", s.is_unique)\n",
    "\n",
    "# 23. Is Monotonic Increasing\n",
    "print(\"Values are monotonic increasing:\", s.is_monotonic_increasing)\n",
    "\n",
    "# 24. Is Monotonic Decreasing\n",
    "print(\"Values are monotonic decreasing:\", s.is_monotonic_decreasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion Methods on Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iinfo(min=-128, max=127, dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using astype method \n",
    "series_1 = pd.Series(data=[12,3,4,5,6,7,8,9])\n",
    "display(series_1.dtype) # default is int64\n",
    "\n",
    "# check the range of int64 using numpy \n",
    "display(np.iinfo('int64')) #iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n",
    "# clearly this is waste of memory \n",
    "display(np.iinfo('int8'))#iinfo(min=-128, max=127, dtype=int8)\n",
    "# Well! int8 is the best fir for our data \n",
    "\n",
    "# convert to int8 \n",
    "series_1 = series_1.astype('int8')\n",
    "display(series_1.dtype) # int8\n",
    "\n",
    "# notics that our data has only positive values and if we know that negative values are not coming then we have uint8\n",
    "np.iinfo('uint8') # iinfo(min=0, max=255, dtype=uint8)\n",
    "\n",
    "# convert to uint8 \n",
    "series_1 = series_1.astype('uint8')\n",
    "display(series_1.dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1e-15\n",
      "Minimum: -1.7976931348623157e+308\n",
      "Maximum: 1.7976931348623157e+308\n",
      "Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# we also have float16 and float64\n",
    "import numpy as np\n",
    "\n",
    "info = np.finfo(np.float64)\n",
    "print(\"Resolution:\", info.resolution)\n",
    "print(\"Minimum:\", info.min)\n",
    "print(\"Maximum:\", info.max)\n",
    "print(\"Data Type:\", info.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `finfo` function in NumPy provides information about floating-point data types, specifically their limits and properties. Here’s a breakdown of the parameters in this example:\n",
    "\n",
    "### Parameters and Properties\n",
    "\n",
    "1. **`resolution=1e-15`**:\n",
    "   - This is the **smallest possible difference** between two distinct floating-point numbers of this type (in this case, `float64`) that can still be represented accurately. The resolution here is set to `1e-15`, meaning that numbers smaller than this difference may be indistinguishable or rounded off due to precision limits. For `float64`, this is typically close to machine epsilon, which is approximately `2.22e-16`.\n",
    "\n",
    "2. **`min=-1.7976931348623157e+308`**:\n",
    "   - This is the **smallest (most negative)** number that can be represented by a `float64` data type. Any number below this will underflow and be represented as `-inf` (negative infinity). For `float64`, this limit is roughly `-1.7976931348623157 × 10^308`.\n",
    "\n",
    "3. **`max=1.7976931348623157e+308`**:\n",
    "   - This is the **largest (most positive)** number that can be represented by a `float64` data type. Any number above this will overflow and be represented as `inf` (positive infinity). The limit for `float64` is approximately `1.7976931348623157 × 10^308`.\n",
    "\n",
    "4. **`dtype=float64`**:\n",
    "   - This specifies the **data type** for which the `finfo` information is given, which in this case is `float64`. `float64` refers to a 64-bit floating-point number, which is the standard for representing floating-point numbers in most computing applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_1 = series_1.astype('float16')\n",
    "print(series_1.dtype)\n",
    "\n",
    "# float16\n",
    "np.finfo('float16') # finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)\n",
    "\n",
    "# note: The resolution takes a large hit! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Conversion matters? - Memory Usage Optimization!\n",
    "\n",
    "To calculate the memory usage of a Pandas Series, you can use either the `.nbytes` property or the `.memory_usage()` method:\n",
    "\n",
    "`.nbytes`:\n",
    "\n",
    "- Shows the memory consumed by the data in the Series alone.\n",
    "- When working with numeric data, changing data types (e.g., from default integer to Int16) can reduce memory usage significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_2 = pd.Series(data=[123, 222, 234, 44, 67, 88, 99, 100, 34, 11, 1001])\n",
    "display(series_2.astype('int64').nbytes) # 88\n",
    "display(series_2.astype('int16').nbytes)  # 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.memory_usage()`:\n",
    "\n",
    "- Includes memory consumed by the Series index and, when used with deep=True, counts the memory of objects stored in the Series.\n",
    "- For object types (like strings), deep=True is needed to include the memory of individual Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_3 = pd.Series(data=['banana', 'orange', 'lichi', 'watermelon', 'guava', 'pineapple', 'banana', 'orange', 'lichi', 'watermelon','lichi', 'watermelon', 'guava','banana', 'orange','pineapple', 'banana', 'orange', 'lichi'])\n",
    "\n",
    "series_3.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Optimization with category Data Type:\n",
    "\n",
    "- Converting object types (like strings) to category can significantly reduce memory usage, as each unique value is stored only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_3.astype('category').memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to Python string:\n",
      " 0       1\n",
      "1       2\n",
      "2       3\n",
      "3    None\n",
      "Name: numeric_str, dtype: object\n",
      "\n",
      "Converted to Pandas string (supports pd.NA):\n",
      " 0     apple\n",
      "1    banana\n",
      "2    cherry\n",
      "3      <NA>\n",
      "Name: string_obj, dtype: string\n",
      "\n",
      "Converted to NumPy int64:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: int_col, dtype: int64\n",
      "\n",
      "Converted to NumPy int32:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: int_col, dtype: int32\n",
      "\n",
      "Converted to Pandas Int64 (supports pd.NA):\n",
      " 0       1\n",
      "1       2\n",
      "2       3\n",
      "3    None\n",
      "Name: int_col_nullable, dtype: object\n",
      "\n",
      "Converted to NumPy float64:\n",
      " 0    1.1\n",
      "1    2.2\n",
      "2    3.3\n",
      "3    NaN\n",
      "Name: float_col, dtype: float64\n",
      "\n",
      "Converted to categorical:\n",
      " 0     apple\n",
      "1    banana\n",
      "2    cherry\n",
      "3      <NA>\n",
      "Name: string_obj, dtype: category\n",
      "Categories (3, string): [apple, banana, cherry]\n",
      "\n",
      "Converted to datetime:\n",
      " 0   2023-01-01\n",
      "1   2023-02-01\n",
      "2          NaT\n",
      "3   2023-04-01\n",
      "Name: date_col, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'numeric_str': ['1', '2', '3', None],\n",
    "    'string_obj': ['apple', 'banana', 'cherry', None],\n",
    "    'int_col': [1, 2, 3, 4],\n",
    "    'float_col': [1.1, 2.2, 3.3, None],\n",
    "})\n",
    "\n",
    "# Converting data types\n",
    "\n",
    "# 1. Converting to Python string type\n",
    "df['numeric_str'] = df['numeric_str'].astype('str')\n",
    "print(\"Converted to Python string:\\n\", df['numeric_str'])\n",
    "\n",
    "# 2. Converting to Pandas string type (supports pd.NA for missing values)\n",
    "df['string_obj'] = df['string_obj'].astype('string')\n",
    "print(\"\\nConverted to Pandas string (supports pd.NA):\\n\", df['string_obj'])\n",
    "\n",
    "# 3. Converting to NumPy int64\n",
    "df['int_col'] = df['int_col'].astype('int64')\n",
    "print(\"\\nConverted to NumPy int64:\\n\", df['int_col'])\n",
    "\n",
    "# 4. Converting to 32-bit signed integer\n",
    "df['int_col'] = df['int_col'].astype('int32')\n",
    "print(\"\\nConverted to NumPy int32:\\n\", df['int_col'])\n",
    "\n",
    "# 5. Converting to Pandas Int64 (supports pd.NA)\n",
    "df['int_col_nullable'] = df['numeric_str'].astype('Int64', errors='ignore')\n",
    "print(\"\\nConverted to Pandas Int64 (supports pd.NA):\\n\", df['int_col_nullable'])\n",
    "\n",
    "# 6. Converting to NumPy float64\n",
    "df['float_col'] = df['float_col'].astype('float64')\n",
    "print(\"\\nConverted to NumPy float64:\\n\", df['float_col'])\n",
    "\n",
    "# 7. Converting to categorical (supports pd.NA)\n",
    "df['string_obj'] = df['string_obj'].astype('category')\n",
    "print(\"\\nConverted to categorical:\\n\", df['string_obj'])\n",
    "\n",
    "# 8. Converting to datetime (not through astype, use pd.to_datetime)\n",
    "df['date_str'] = ['2023-01-01', '2023-02-01', None, '2023-04-01']\n",
    "df['date_col'] = pd.to_datetime(df['date_str'])\n",
    "print(\"\\nConverted to datetime:\\n\", df['date_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to appropriate pandas types (supports NA):\n",
      " 0        1\n",
      "1        2\n",
      "2     None\n",
      "3        4\n",
      "4        5\n",
      "5    apple\n",
      "6     True\n",
      "dtype: object\n",
      "\n",
      "Casted to pandas Int64 with NA support:\n",
      " 0       1\n",
      "1       2\n",
      "2    <NA>\n",
      "3       4\n",
      "dtype: Int64\n",
      "\n",
      "Converted to datetime:\n",
      " 0   2023-01-01\n",
      "1   2023-02-01\n",
      "2          NaT\n",
      "3   2023-04-01\n",
      "dtype: datetime64[ns]\n",
      "\n",
      "Converted to NumPy array with specified NA handling:\n",
      " [1 2 nan 4 '5' 'apple' True]\n",
      "\n",
      "Converted to NumPy array using .values:\n",
      " [1 2 None 4 '5' 'apple' True]\n",
      "\n",
      "Converted to DataFrame:\n",
      "   column_name\n",
      "0           1\n",
      "1           2\n",
      "2        None\n",
      "3           4\n",
      "4           5\n",
      "5       apple\n",
      "6        True\n",
      "\n",
      "Series with categorical data type:\n",
      " 0     apple\n",
      "1    cherry\n",
      "2    banana\n",
      "3     apple\n",
      "dtype: category\n",
      "Categories (3, object): ['apple' < 'banana' < 'cherry']\n"
     ]
    }
   ],
   "source": [
    "# Some other conversions\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series([1, 2, None, 4, '5', 'apple', True])\n",
    "\n",
    "# 1. Convert types using .convert_dtypes (Pandas 1.x types supporting pd.NA)\n",
    "s_converted = s.convert_dtypes(\n",
    "    infer_objects=True,\n",
    "    convert_string=True,\n",
    "    convert_integer=True,\n",
    "    convert_boolean=True,\n",
    "    convert_floating=True\n",
    ")\n",
    "print(\"Converted to appropriate pandas types (supports NA):\\n\", s_converted)\n",
    "\n",
    "# 2. Cast Series to a specific type using .astype\n",
    "s_int = pd.Series(['1', '2', None, '4']).astype(dtype='Int64', errors='ignore')\n",
    "print(\"\\nCasted to pandas Int64 with NA support:\\n\", s_int)\n",
    "\n",
    "# 3. Convert to datetime using pd.to_datetime\n",
    "date_series = pd.Series(['2023-01-01', '2023-02-01', None, '2023-04-01'])\n",
    "date_converted = pd.to_datetime(date_series, errors='raise', dayfirst=False, yearfirst=False)\n",
    "print(\"\\nConverted to datetime:\\n\", date_converted)\n",
    "\n",
    "# 4. Convert Series to NumPy array using .to_numpy\n",
    "numpy_array = s.to_numpy(dtype=object, copy=True, na_value=np.nan)\n",
    "print(\"\\nConverted to NumPy array with specified NA handling:\\n\", numpy_array)\n",
    "\n",
    "# 5. Convert Series to NumPy array using .values (similar to .to_numpy)\n",
    "numpy_values = s.values\n",
    "print(\"\\nConverted to NumPy array using .values:\\n\", numpy_values)\n",
    "\n",
    "# 6. Convert Series to DataFrame using .to_frame\n",
    "s_dataframe = s.to_frame(name='column_name')\n",
    "print(\"\\nConverted to DataFrame:\\n\", s_dataframe)\n",
    "\n",
    "# 7. Define categorical data type using pd.CategoricalDtype\n",
    "cat_type = pd.CategoricalDtype(categories=['apple', 'banana', 'cherry'], ordered=True)\n",
    "s_cat = pd.Series(['apple', 'cherry', 'banana', 'apple'], dtype=cat_type)\n",
    "print(\"\\nSeries with categorical data type:\\n\", s_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation Methods on Series\n",
    "\n",
    "Before starting with manipulation methods in the pandas Series object, let us breifly understand the usage of the lambda function in Python along with map, filter, reduce!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda functions (in general)\n",
    "\n",
    "Lambda functions, also known as anonymous functions, are small, single-expression functions defined with the `lambda` keyword in Python. Unlike standard functions created using `def`, lambda functions don’t require a name and are typically used for quick, throwaway functions that are needed for a short period.\n",
    "\n",
    "### Basic Syntax of Lambda Functions\n",
    "\n",
    "The syntax for a lambda function is as follows:\n",
    "\n",
    "```python\n",
    "lambda arguments: expression\n",
    "```\n",
    "\n",
    "- **Arguments**: Lambda functions can have any number of arguments (including zero).\n",
    "- **Expression**: A single expression that the function evaluates and returns as the result. No explicit `return` statement is needed; the value of the expression is automatically returned.\n",
    "\n",
    "### Example of a Lambda Function\n",
    "\n",
    "Here’s a simple example:\n",
    "\n",
    "```python\n",
    "add = lambda x, y: x + y\n",
    "print(add(2, 3))  # Output: 5\n",
    "```\n",
    "\n",
    "This creates an anonymous function to add two numbers and assigns it to the variable `add`. The function takes two arguments, `x` and `y`, and returns their sum.\n",
    "\n",
    "## General syntax for `filter`, `map`, and `reduce` in Python, often used with lambda functions or other callable objects.\n",
    "\n",
    "### 1. `filter(function, iterable)`\n",
    "\n",
    "The `filter` function applies a filtering condition to an iterable. It returns only the items for which the condition evaluates to `True`.\n",
    "\n",
    "```python\n",
    "filtered_iterable = filter(function, iterable)\n",
    "```\n",
    "\n",
    "- **function**: A function that returns `True` or `False` for each item in the iterable.\n",
    "- **iterable**: The data to filter (e.g., a list or tuple).\n",
    "- **Returns**: An iterator of elements for which the function returns `True`.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(even_numbers)  # Output: [2, 4]\n",
    "```\n",
    "\n",
    "### 2. `map(function, iterable)`\n",
    "\n",
    "The `map` function applies a function to each item in an iterable and returns a map object with the results.\n",
    "\n",
    "```python\n",
    "mapped_iterable = map(function, iterable)\n",
    "```\n",
    "\n",
    "- **function**: A function to apply to each element of the iterable.\n",
    "- **iterable**: The data to transform (e.g., a list or tuple).\n",
    "- **Returns**: An iterator with the results of applying the function to each element.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "squared_numbers = list(map(lambda x: x ** 2, numbers))\n",
    "print(squared_numbers)  # Output: [1, 4, 9, 16]\n",
    "```\n",
    "\n",
    "### 3. `reduce(function, iterable, initializer=None)`\n",
    "\n",
    "The `reduce` function applies a rolling computation to the elements of an iterable, reducing the iterable to a single cumulative result. `reduce` is found in the `functools` module.\n",
    "\n",
    "```python\n",
    "from functools import reduce\n",
    "result = reduce(function, iterable, initializer)\n",
    "```\n",
    "\n",
    "- **function**: A function of two arguments, applied cumulatively to reduce the iterable.\n",
    "- **iterable**: The data to reduce (e.g., a list or tuple).\n",
    "- **initializer** (optional): A starting value for the reduction; if provided, it’s placed before the first element.\n",
    "- **Returns**: A single value obtained by reducing the iterable.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "product = reduce(lambda x, y: x * y, numbers)\n",
    "print(product)  # Output: 24 (1 * 2 * 3 * 4)\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "These functions are useful for data processing:\n",
    "\n",
    "- **`filter`**: Selects elements based on a condition.\n",
    "- **`map`**: Transforms each element.\n",
    "- **`reduce`**: Aggregates all elements into a single result.\n",
    "\n",
    "### Use Cases for Lambda Functions\n",
    "\n",
    "Lambda functions are often used in places where short, simple functions are required. Common use cases include:\n",
    "\n",
    "1. **Sorting with custom keys**:\n",
    "   ```python\n",
    "   points = [(1, 2), (3, 1), (5, -1)]\n",
    "   points.sort(key=lambda x: x[1])\n",
    "   print(points)  # Sorted by the second item: [(5, -1), (3, 1), (1, 2)]\n",
    "   ```\n",
    "\n",
    "2. **Filtering data**:\n",
    "   ```python\n",
    "   numbers = [1, 2, 3, 4, 5, 6]\n",
    "   even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "   print(even_numbers)  # Output: [2, 4, 6]\n",
    "   ```\n",
    "\n",
    "3. **Mapping transformations**:\n",
    "   ```python\n",
    "   numbers = [1, 2, 3, 4]\n",
    "   squares = list(map(lambda x: x ** 2, numbers))\n",
    "   print(squares)  # Output: [1, 4, 9, 16]\n",
    "   ```\n",
    "\n",
    "4. **Combining with functions like `reduce`**:\n",
    "   ```python\n",
    "   from functools import reduce\n",
    "   numbers = [1, 2, 3, 4]\n",
    "   product = reduce(lambda x, y: x * y, numbers)\n",
    "   print(product)  # Output: 24\n",
    "   ```\n",
    "\n",
    "### Comparison with `def` Functions\n",
    "\n",
    "Lambda functions are syntactically restricted to a single expression, while `def` functions can contain multiple statements, more complex logic, and documentation strings.\n",
    "\n",
    "**Lambda function**:\n",
    "```python\n",
    "double = lambda x: x * 2\n",
    "```\n",
    "\n",
    "**def function**:\n",
    "```python\n",
    "def double(x):\n",
    "    return x * 2\n",
    "```\n",
    "\n",
    "### Advantages of Lambda Functions\n",
    "\n",
    "- **Concise and Inline**: Useful for quick, small operations that can be defined in one line.\n",
    "- **Anonymous**: Lambda functions can be created without names, making them convenient for immediate use and disposal.\n",
    "\n",
    "### Limitations of Lambda Functions\n",
    "\n",
    "- **Single Expression**: Lambda functions are limited to a single expression and can't contain statements.\n",
    "- **Readability**: They can sometimes make the code harder to read, especially if overused or used in complex expressions.\n",
    "\n",
    "### Using Lambda Functions with Higher-Order Functions\n",
    "\n",
    "Lambda functions are commonly used with higher-order functions like `map`, `filter`, and `sorted`, as they allow you to create custom behaviors on-the-fly:\n",
    "\n",
    "```python\n",
    "# Using map with lambda\n",
    "nums = [1, 2, 3, 4]\n",
    "doubled = list(map(lambda x: x * 2, nums))\n",
    "print(doubled)  # Output: [2, 4, 6, 8]\n",
    "```\n",
    "\n",
    "### Nesting Lambda Functions\n",
    "\n",
    "Lambda functions can also be nested, which can be useful for creating custom key functions for sorting and grouping:\n",
    "\n",
    "```python\n",
    "# Nested lambda for sorting\n",
    "students = [('Alice', 85), ('Bob', 70), ('Charlie', 90)]\n",
    "sorted_students = sorted(students, key=lambda x: (x[1], x[0]))\n",
    "print(sorted_students)  # Sorts by score first, then by name\n",
    "```\n",
    "\n",
    "### Practical Example: Lambda in Data Processing\n",
    "\n",
    "Consider a list of dictionary entries, where we want to filter and transform certain data in a pipeline-like manner:\n",
    "\n",
    "```python\n",
    "people = [\n",
    "    {'name': 'Alice', 'age': 28},\n",
    "    {'name': 'Bob', 'age': 23},\n",
    "    {'name': 'Charlie', 'age': 25},\n",
    "]\n",
    "\n",
    "# Filtering people aged 25 or older, then extracting names\n",
    "names = list(map(lambda person: person['name'],\n",
    "                 filter(lambda person: person['age'] >= 25, people)))\n",
    "print(names)  # Output: ['Alice', 'Charlie']\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Lambda functions provide a convenient way to create small, simple functions without the need to formally define them. While useful in many scenarios, they’re best used sparingly in cases where a `def` function might be overkill, such as for short, one-off functions in data processing or as arguments to higher-order functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
