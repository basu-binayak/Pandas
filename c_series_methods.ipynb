{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Operations on Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation with mean: 31.666666666666668\n",
      "Aggregation with multiple functions:\n",
      " mean    31.666667\n",
      "min     10.000000\n",
      "max     60.000000\n",
      "dtype: float64\n",
      "All values are truthy: True\n",
      "At least one value is truthy: True\n",
      "Autocorrelation: 0.7433046224826585\n",
      "Pearson correlation with s2: 0.9254821475438165\n",
      "Covariance with s2: 370.0\n",
      "Maximum value: 60\n",
      "Minimum value: 10\n",
      "Mean value: 31.666666666666668\n",
      "Median value: 30.0\n",
      "Product of values: 240000000\n",
      "50% Quantile: 30.0\n",
      "Quantiles: \n",
      " 0.1    10.0\n",
      "0.5    30.0\n",
      "0.9    55.0\n",
      "dtype: float64\n",
      "Standard error of mean: 8.724168218868268\n",
      "Standard deviation: 21.36976056643281\n",
      "Variance: 456.6666666666667\n",
      "Skewness: 0.23226763043061902\n",
      "Kurtosis: -2.149821514198946\n",
      "Count of unique items: 5\n",
      "Count of non-missing items: 6\n",
      "Size of Series: 6\n",
      "All values are unique: False\n",
      "Values are monotonic increasing: False\n",
      "Values are monotonic decreasing: False\n"
     ]
    }
   ],
   "source": [
    "# Example Series\n",
    "s = pd.Series([10, 20, 10, 40, 50, 60])\n",
    "\n",
    "# 1. Aggregation (single function returns scalar, list of functions returns Series)\n",
    "print(\"Aggregation with mean:\", s.agg('mean'))\n",
    "print(\"Aggregation with multiple functions:\\n\", s.agg(['mean', 'min', 'max']))\n",
    "\n",
    "# 2. All: Returns True if every value is truthy\n",
    "print(\"All values are truthy:\", s.all())\n",
    "\n",
    "# 3. Any: Returns True if at least one value is truthy\n",
    "print(\"At least one value is truthy:\", s.any())\n",
    "\n",
    "# 4. Autocorrelation with lag=1\n",
    "print(\"Autocorrelation:\", s.autocorr(lag=1))\n",
    "\n",
    "# 5. Correlation with another Series\n",
    "s2 = pd.Series([10, 20, 30, 40, 50, 60])\n",
    "print(\"Pearson correlation with s2:\", s.corr(s2))\n",
    "\n",
    "# 6. Covariance with another Series\n",
    "print(\"Covariance with s2:\", s.cov(s2))\n",
    "\n",
    "# 7. Max: Returns maximum value\n",
    "print(\"Maximum value:\", s.max())\n",
    "\n",
    "# 8. Min: Returns minimum value\n",
    "print(\"Minimum value:\", s.min())\n",
    "\n",
    "# 9. Mean: Returns mean value\n",
    "print(\"Mean value:\", s.mean())\n",
    "\n",
    "# 10. Median: Returns median value\n",
    "print(\"Median value:\", s.median())\n",
    "\n",
    "# 11. Product: Returns product of values\n",
    "print(\"Product of values:\", s.prod())\n",
    "\n",
    "# 12. Quantile: Returns specified quantile\n",
    "print(\"50% Quantile:\", s.quantile(q=0.5))\n",
    "print(\"Quantiles: \\n\", s.quantile(q=[.1 , .5, .9])) # returns a series \n",
    "\n",
    "# 13. Standard Error of Mean (SEM)\n",
    "print(\"Standard error of mean:\", s.sem())\n",
    "\n",
    "# 14. Standard Deviation\n",
    "print(\"Standard deviation:\", s.std())\n",
    "\n",
    "# 15. Variance\n",
    "print(\"Variance:\", s.var())\n",
    "\n",
    "# 16. Skewness\n",
    "print(\"Skewness:\", s.skew())\n",
    "\n",
    "# 17. Kurtosis\n",
    "print(\"Kurtosis:\", s.kurtosis())\n",
    "\n",
    "# 18. Count of unique items\n",
    "print(\"Count of unique items:\", s.nunique())\n",
    "\n",
    "# 19. Count of non-missing items\n",
    "print(\"Count of non-missing items:\", s.count())\n",
    "\n",
    "# 20. Size: Number of items in Series\n",
    "print(\"Size of Series:\", s.size)\n",
    "\n",
    "# 21. Is Unique: Check if all values are unique\n",
    "print(\"All values are unique:\", s.is_unique)\n",
    "\n",
    "# 23. Is Monotonic Increasing\n",
    "print(\"Values are monotonic increasing:\", s.is_monotonic_increasing)\n",
    "\n",
    "# 24. Is Monotonic Decreasing\n",
    "print(\"Values are monotonic decreasing:\", s.is_monotonic_decreasing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion Methods on Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iinfo(min=-128, max=127, dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using astype method \n",
    "series_1 = pd.Series(data=[12,3,4,5,6,7,8,9])\n",
    "display(series_1.dtype) # default is int64\n",
    "\n",
    "# check the range of int64 using numpy \n",
    "display(np.iinfo('int64')) #iinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n",
    "# clearly this is waste of memory \n",
    "display(np.iinfo('int8'))#iinfo(min=-128, max=127, dtype=int8)\n",
    "# Well! int8 is the best fir for our data \n",
    "\n",
    "# convert to int8 \n",
    "series_1 = series_1.astype('int8')\n",
    "display(series_1.dtype) # int8\n",
    "\n",
    "# notics that our data has only positive values and if we know that negative values are not coming then we have uint8\n",
    "np.iinfo('uint8') # iinfo(min=0, max=255, dtype=uint8)\n",
    "\n",
    "# convert to uint8 \n",
    "series_1 = series_1.astype('uint8')\n",
    "display(series_1.dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1e-15\n",
      "Minimum: -1.7976931348623157e+308\n",
      "Maximum: 1.7976931348623157e+308\n",
      "Data Type: float64\n"
     ]
    }
   ],
   "source": [
    "# we also have float16 and float64\n",
    "import numpy as np\n",
    "\n",
    "info = np.finfo(np.float64)\n",
    "print(\"Resolution:\", info.resolution)\n",
    "print(\"Minimum:\", info.min)\n",
    "print(\"Maximum:\", info.max)\n",
    "print(\"Data Type:\", info.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `finfo` function in NumPy provides information about floating-point data types, specifically their limits and properties. Here’s a breakdown of the parameters in this example:\n",
    "\n",
    "### Parameters and Properties\n",
    "\n",
    "1. **`resolution=1e-15`**:\n",
    "   - This is the **smallest possible difference** between two distinct floating-point numbers of this type (in this case, `float64`) that can still be represented accurately. The resolution here is set to `1e-15`, meaning that numbers smaller than this difference may be indistinguishable or rounded off due to precision limits. For `float64`, this is typically close to machine epsilon, which is approximately `2.22e-16`.\n",
    "\n",
    "2. **`min=-1.7976931348623157e+308`**:\n",
    "   - This is the **smallest (most negative)** number that can be represented by a `float64` data type. Any number below this will underflow and be represented as `-inf` (negative infinity). For `float64`, this limit is roughly `-1.7976931348623157 × 10^308`.\n",
    "\n",
    "3. **`max=1.7976931348623157e+308`**:\n",
    "   - This is the **largest (most positive)** number that can be represented by a `float64` data type. Any number above this will overflow and be represented as `inf` (positive infinity). The limit for `float64` is approximately `1.7976931348623157 × 10^308`.\n",
    "\n",
    "4. **`dtype=float64`**:\n",
    "   - This specifies the **data type** for which the `finfo` information is given, which in this case is `float64`. `float64` refers to a 64-bit floating-point number, which is the standard for representing floating-point numbers in most computing applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_1 = series_1.astype('float16')\n",
    "print(series_1.dtype)\n",
    "\n",
    "# float16\n",
    "np.finfo('float16') # finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)\n",
    "\n",
    "# note: The resolution takes a large hit! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Conversion matters? - Memory Usage Optimization!\n",
    "\n",
    "To calculate the memory usage of a Pandas Series, you can use either the `.nbytes` property or the `.memory_usage()` method:\n",
    "\n",
    "`.nbytes`:\n",
    "\n",
    "- Shows the memory consumed by the data in the Series alone.\n",
    "- When working with numeric data, changing data types (e.g., from default integer to Int16) can reduce memory usage significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_2 = pd.Series(data=[123, 222, 234, 44, 67, 88, 99, 100, 34, 11, 1001])\n",
    "display(series_2.astype('int64').nbytes) # 88\n",
    "display(series_2.astype('int16').nbytes)  # 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.memory_usage()`:\n",
    "\n",
    "- Includes memory consumed by the Series index and, when used with deep=True, counts the memory of objects stored in the Series.\n",
    "- For object types (like strings), deep=True is needed to include the memory of individual Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_3 = pd.Series(data=['banana', 'orange', 'lichi', 'watermelon', 'guava', 'pineapple', 'banana', 'orange', 'lichi', 'watermelon','lichi', 'watermelon', 'guava','banana', 'orange','pineapple', 'banana', 'orange', 'lichi'])\n",
    "\n",
    "series_3.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Optimization with category Data Type:\n",
    "\n",
    "- Converting object types (like strings) to category can significantly reduce memory usage, as each unique value is stored only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_3.astype('category').memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to Python string:\n",
      " 0       1\n",
      "1       2\n",
      "2       3\n",
      "3    None\n",
      "Name: numeric_str, dtype: object\n",
      "\n",
      "Converted to Pandas string (supports pd.NA):\n",
      " 0     apple\n",
      "1    banana\n",
      "2    cherry\n",
      "3      <NA>\n",
      "Name: string_obj, dtype: string\n",
      "\n",
      "Converted to NumPy int64:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: int_col, dtype: int64\n",
      "\n",
      "Converted to NumPy int32:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "Name: int_col, dtype: int32\n",
      "\n",
      "Converted to Pandas Int64 (supports pd.NA):\n",
      " 0       1\n",
      "1       2\n",
      "2       3\n",
      "3    None\n",
      "Name: int_col_nullable, dtype: object\n",
      "\n",
      "Converted to NumPy float64:\n",
      " 0    1.1\n",
      "1    2.2\n",
      "2    3.3\n",
      "3    NaN\n",
      "Name: float_col, dtype: float64\n",
      "\n",
      "Converted to categorical:\n",
      " 0     apple\n",
      "1    banana\n",
      "2    cherry\n",
      "3      <NA>\n",
      "Name: string_obj, dtype: category\n",
      "Categories (3, string): [apple, banana, cherry]\n",
      "\n",
      "Converted to datetime:\n",
      " 0   2023-01-01\n",
      "1   2023-02-01\n",
      "2          NaT\n",
      "3   2023-04-01\n",
      "Name: date_col, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'numeric_str': ['1', '2', '3', None],\n",
    "    'string_obj': ['apple', 'banana', 'cherry', None],\n",
    "    'int_col': [1, 2, 3, 4],\n",
    "    'float_col': [1.1, 2.2, 3.3, None],\n",
    "})\n",
    "\n",
    "# Converting data types\n",
    "\n",
    "# 1. Converting to Python string type\n",
    "df['numeric_str'] = df['numeric_str'].astype('str')\n",
    "print(\"Converted to Python string:\\n\", df['numeric_str'])\n",
    "\n",
    "# 2. Converting to Pandas string type (supports pd.NA for missing values)\n",
    "df['string_obj'] = df['string_obj'].astype('string')\n",
    "print(\"\\nConverted to Pandas string (supports pd.NA):\\n\", df['string_obj'])\n",
    "\n",
    "# 3. Converting to NumPy int64\n",
    "df['int_col'] = df['int_col'].astype('int64')\n",
    "print(\"\\nConverted to NumPy int64:\\n\", df['int_col'])\n",
    "\n",
    "# 4. Converting to 32-bit signed integer\n",
    "df['int_col'] = df['int_col'].astype('int32')\n",
    "print(\"\\nConverted to NumPy int32:\\n\", df['int_col'])\n",
    "\n",
    "# 5. Converting to Pandas Int64 (supports pd.NA)\n",
    "df['int_col_nullable'] = df['numeric_str'].astype('Int64', errors='ignore')\n",
    "print(\"\\nConverted to Pandas Int64 (supports pd.NA):\\n\", df['int_col_nullable'])\n",
    "\n",
    "# 6. Converting to NumPy float64\n",
    "df['float_col'] = df['float_col'].astype('float64')\n",
    "print(\"\\nConverted to NumPy float64:\\n\", df['float_col'])\n",
    "\n",
    "# 7. Converting to categorical (supports pd.NA)\n",
    "df['string_obj'] = df['string_obj'].astype('category')\n",
    "print(\"\\nConverted to categorical:\\n\", df['string_obj'])\n",
    "\n",
    "# 8. Converting to datetime (not through astype, use pd.to_datetime)\n",
    "df['date_str'] = ['2023-01-01', '2023-02-01', None, '2023-04-01']\n",
    "df['date_col'] = pd.to_datetime(df['date_str'])\n",
    "print(\"\\nConverted to datetime:\\n\", df['date_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to appropriate pandas types (supports NA):\n",
      " 0        1\n",
      "1        2\n",
      "2     None\n",
      "3        4\n",
      "4        5\n",
      "5    apple\n",
      "6     True\n",
      "dtype: object\n",
      "\n",
      "Casted to pandas Int64 with NA support:\n",
      " 0       1\n",
      "1       2\n",
      "2    <NA>\n",
      "3       4\n",
      "dtype: Int64\n",
      "\n",
      "Converted to datetime:\n",
      " 0   2023-01-01\n",
      "1   2023-02-01\n",
      "2          NaT\n",
      "3   2023-04-01\n",
      "dtype: datetime64[ns]\n",
      "\n",
      "Converted to NumPy array with specified NA handling:\n",
      " [1 2 nan 4 '5' 'apple' True]\n",
      "\n",
      "Converted to NumPy array using .values:\n",
      " [1 2 None 4 '5' 'apple' True]\n",
      "\n",
      "Converted to DataFrame:\n",
      "   column_name\n",
      "0           1\n",
      "1           2\n",
      "2        None\n",
      "3           4\n",
      "4           5\n",
      "5       apple\n",
      "6        True\n",
      "\n",
      "Series with categorical data type:\n",
      " 0     apple\n",
      "1    cherry\n",
      "2    banana\n",
      "3     apple\n",
      "dtype: category\n",
      "Categories (3, object): ['apple' < 'banana' < 'cherry']\n"
     ]
    }
   ],
   "source": [
    "# Some other conversions\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series([1, 2, None, 4, '5', 'apple', True])\n",
    "\n",
    "# 1. Convert types using .convert_dtypes (Pandas 1.x types supporting pd.NA)\n",
    "s_converted = s.convert_dtypes(\n",
    "    infer_objects=True,\n",
    "    convert_string=True,\n",
    "    convert_integer=True,\n",
    "    convert_boolean=True,\n",
    "    convert_floating=True\n",
    ")\n",
    "print(\"Converted to appropriate pandas types (supports NA):\\n\", s_converted)\n",
    "\n",
    "# 2. Cast Series to a specific type using .astype\n",
    "s_int = pd.Series(['1', '2', None, '4']).astype(dtype='Int64', errors='ignore')\n",
    "print(\"\\nCasted to pandas Int64 with NA support:\\n\", s_int)\n",
    "\n",
    "# 3. Convert to datetime using pd.to_datetime\n",
    "date_series = pd.Series(['2023-01-01', '2023-02-01', None, '2023-04-01'])\n",
    "date_converted = pd.to_datetime(date_series, errors='raise', dayfirst=False, yearfirst=False)\n",
    "print(\"\\nConverted to datetime:\\n\", date_converted)\n",
    "\n",
    "# 4. Convert Series to NumPy array using .to_numpy\n",
    "numpy_array = s.to_numpy(dtype=object, copy=True, na_value=np.nan)\n",
    "print(\"\\nConverted to NumPy array with specified NA handling:\\n\", numpy_array)\n",
    "\n",
    "# 5. Convert Series to NumPy array using .values (similar to .to_numpy)\n",
    "numpy_values = s.values\n",
    "print(\"\\nConverted to NumPy array using .values:\\n\", numpy_values)\n",
    "\n",
    "# 6. Convert Series to DataFrame using .to_frame\n",
    "s_dataframe = s.to_frame(name='column_name')\n",
    "print(\"\\nConverted to DataFrame:\\n\", s_dataframe)\n",
    "\n",
    "# 7. Define categorical data type using pd.CategoricalDtype\n",
    "cat_type = pd.CategoricalDtype(categories=['apple', 'banana', 'cherry'], ordered=True)\n",
    "s_cat = pd.Series(['apple', 'cherry', 'banana', 'apple'], dtype=cat_type)\n",
    "print(\"\\nSeries with categorical data type:\\n\", s_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.1\n",
      "1    2.7\n",
      "2    1.4\n",
      "dtype: float64\n",
      "0    3.000\n",
      "1    2.718\n",
      "2    2.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([3.141, 2.718, 1.414])\n",
    "print(s.round(1))     # Round to 1 decimal\n",
    "print(s.clip(2, 3))   # Force values between 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation Methods on Series\n",
    "\n",
    "Before starting with manipulation methods in the pandas Series object, let us breifly understand the usage of the lambda function in Python along with map, filter, reduce!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda functions (in general)\n",
    "\n",
    "Lambda functions, also known as anonymous functions, are small, single-expression functions defined with the `lambda` keyword in Python. Unlike standard functions created using `def`, lambda functions don’t require a name and are typically used for quick, throwaway functions that are needed for a short period.\n",
    "\n",
    "### Basic Syntax of Lambda Functions\n",
    "\n",
    "The syntax for a lambda function is as follows:\n",
    "\n",
    "```python\n",
    "lambda arguments: expression\n",
    "```\n",
    "\n",
    "- **Arguments**: Lambda functions can have any number of arguments (including zero).\n",
    "- **Expression**: A single expression that the function evaluates and returns as the result. No explicit `return` statement is needed; the value of the expression is automatically returned.\n",
    "\n",
    "### Example of a Lambda Function\n",
    "\n",
    "Here’s a simple example:\n",
    "\n",
    "```python\n",
    "add = lambda x, y: x + y\n",
    "print(add(2, 3))  # Output: 5\n",
    "```\n",
    "\n",
    "This creates an anonymous function to add two numbers and assigns it to the variable `add`. The function takes two arguments, `x` and `y`, and returns their sum.\n",
    "\n",
    "## General syntax for `filter`, `map`, and `reduce` in Python, often used with lambda functions or other callable objects.\n",
    "\n",
    "### 1. `filter(function, iterable)`\n",
    "\n",
    "The `filter` function applies a filtering condition to an iterable. It returns only the items for which the condition evaluates to `True`.\n",
    "\n",
    "```python\n",
    "filtered_iterable = filter(function, iterable)\n",
    "```\n",
    "\n",
    "- **function**: A function that returns `True` or `False` for each item in the iterable.\n",
    "- **iterable**: The data to filter (e.g., a list or tuple).\n",
    "- **Returns**: An iterator of elements for which the function returns `True`.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(even_numbers)  # Output: [2, 4]\n",
    "```\n",
    "\n",
    "### 2. `map(function, iterable)`\n",
    "\n",
    "The `map` function applies a function to each item in an iterable and returns a map object with the results.\n",
    "\n",
    "```python\n",
    "mapped_iterable = map(function, iterable)\n",
    "```\n",
    "\n",
    "- **function**: A function to apply to each element of the iterable.\n",
    "- **iterable**: The data to transform (e.g., a list or tuple).\n",
    "- **Returns**: An iterator with the results of applying the function to each element.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "squared_numbers = list(map(lambda x: x ** 2, numbers))\n",
    "print(squared_numbers)  # Output: [1, 4, 9, 16]\n",
    "```\n",
    "\n",
    "### 3. `reduce(function, iterable, initializer=None)`\n",
    "\n",
    "The `reduce` function applies a rolling computation to the elements of an iterable, reducing the iterable to a single cumulative result. `reduce` is found in the `functools` module.\n",
    "\n",
    "```python\n",
    "from functools import reduce\n",
    "result = reduce(function, iterable, initializer)\n",
    "```\n",
    "\n",
    "- **function**: A function of two arguments, applied cumulatively to reduce the iterable.\n",
    "- **iterable**: The data to reduce (e.g., a list or tuple).\n",
    "- **initializer** (optional): A starting value for the reduction; if provided, it’s placed before the first element.\n",
    "- **Returns**: A single value obtained by reducing the iterable.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "product = reduce(lambda x, y: x * y, numbers)\n",
    "print(product)  # Output: 24 (1 * 2 * 3 * 4)\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "These functions are useful for data processing:\n",
    "\n",
    "- **`filter`**: Selects elements based on a condition.\n",
    "- **`map`**: Transforms each element.\n",
    "- **`reduce`**: Aggregates all elements into a single result.\n",
    "\n",
    "### Use Cases for Lambda Functions\n",
    "\n",
    "Lambda functions are often used in places where short, simple functions are required. Common use cases include:\n",
    "\n",
    "1. **Sorting with custom keys**:\n",
    "   ```python\n",
    "   points = [(1, 2), (3, 1), (5, -1)]\n",
    "   points.sort(key=lambda x: x[1])\n",
    "   print(points)  # Sorted by the second item: [(5, -1), (3, 1), (1, 2)]\n",
    "   ```\n",
    "\n",
    "2. **Filtering data**:\n",
    "   ```python\n",
    "   numbers = [1, 2, 3, 4, 5, 6]\n",
    "   even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "   print(even_numbers)  # Output: [2, 4, 6]\n",
    "   ```\n",
    "\n",
    "3. **Mapping transformations**:\n",
    "   ```python\n",
    "   numbers = [1, 2, 3, 4]\n",
    "   squares = list(map(lambda x: x ** 2, numbers))\n",
    "   print(squares)  # Output: [1, 4, 9, 16]\n",
    "   ```\n",
    "\n",
    "4. **Combining with functions like `reduce`**:\n",
    "   ```python\n",
    "   from functools import reduce\n",
    "   numbers = [1, 2, 3, 4]\n",
    "   product = reduce(lambda x, y: x * y, numbers)\n",
    "   print(product)  # Output: 24\n",
    "   ```\n",
    "\n",
    "### Comparison with `def` Functions\n",
    "\n",
    "Lambda functions are syntactically restricted to a single expression, while `def` functions can contain multiple statements, more complex logic, and documentation strings.\n",
    "\n",
    "**Lambda function**:\n",
    "```python\n",
    "double = lambda x: x * 2\n",
    "```\n",
    "\n",
    "**def function**:\n",
    "```python\n",
    "def double(x):\n",
    "    return x * 2\n",
    "```\n",
    "\n",
    "### Advantages of Lambda Functions\n",
    "\n",
    "- **Concise and Inline**: Useful for quick, small operations that can be defined in one line.\n",
    "- **Anonymous**: Lambda functions can be created without names, making them convenient for immediate use and disposal.\n",
    "\n",
    "### Limitations of Lambda Functions\n",
    "\n",
    "- **Single Expression**: Lambda functions are limited to a single expression and can't contain statements.\n",
    "- **Readability**: They can sometimes make the code harder to read, especially if overused or used in complex expressions.\n",
    "\n",
    "### Using Lambda Functions with Higher-Order Functions\n",
    "\n",
    "Lambda functions are commonly used with higher-order functions like `map`, `filter`, and `sorted`, as they allow you to create custom behaviors on-the-fly:\n",
    "\n",
    "```python\n",
    "# Using map with lambda\n",
    "nums = [1, 2, 3, 4]\n",
    "doubled = list(map(lambda x: x * 2, nums))\n",
    "print(doubled)  # Output: [2, 4, 6, 8]\n",
    "```\n",
    "\n",
    "### Nesting Lambda Functions\n",
    "\n",
    "Lambda functions can also be nested, which can be useful for creating custom key functions for sorting and grouping:\n",
    "\n",
    "```python\n",
    "# Nested lambda for sorting\n",
    "students = [('Alice', 85), ('Bob', 70), ('Charlie', 90)]\n",
    "sorted_students = sorted(students, key=lambda x: (x[1], x[0]))\n",
    "print(sorted_students)  # Sorts by score first, then by name\n",
    "```\n",
    "\n",
    "### Practical Example: Lambda in Data Processing\n",
    "\n",
    "Consider a list of dictionary entries, where we want to filter and transform certain data in a pipeline-like manner:\n",
    "\n",
    "```python\n",
    "people = [\n",
    "    {'name': 'Alice', 'age': 28},\n",
    "    {'name': 'Bob', 'age': 23},\n",
    "    {'name': 'Charlie', 'age': 25},\n",
    "]\n",
    "\n",
    "# Filtering people aged 25 or older, then extracting names\n",
    "names = list(map(lambda person: person['name'],\n",
    "                 filter(lambda person: person['age'] >= 25, people)))\n",
    "print(names)  # Output: ['Alice', 'Charlie']\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Lambda functions provide a convenient way to create small, simple functions without the need to formally define them. While useful in many scenarios, they’re best used sparingly in cases where a `def` function might be overkill, such as for short, one-off functions in data processing or as arguments to higher-order functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([54. , 58. , 55. , 66. , 49. , 65. , 46. , 59. , 71. , 47. , 70.5,\n",
       "       54. , 47. , 51. , 55.5, 51. , 61. , 56. , 50. , 58. , 45.5, 51. ,\n",
       "       59. , 54. , 62. , 50. , 52. , 58. , 63. , 65. , 50. , 54. , 61. ,\n",
       "       45.5, 60. , 46. , 51. , 50. , 64. , 52. , 49. , 65. , 50. , 48. ,\n",
       "       47. , 48. , 56. , 50. , 63. , 58. , 55. , 71. , 54. , 54. , 47. ,\n",
       "       50. , 50. , 64. , 62. , 48. , 62. , 53. , 54. , 47. , 60. , 52. ,\n",
       "       47. , 49. , 49. , 61. , 57. , 80. , 51. , 48. , 56. , 58. , 50. ,\n",
       "       47. , 70. , 60. , 60. , 52. , 49. , 48. , 52. , 50. , 48. , 70. ,\n",
       "       48. , 51. , 48. , 57. , 54. , 46. , 49. , 52. , 62. , 74. , 51. ,\n",
       "       48. , 47. , 47. , 56. ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_age = df['Age'] # this is a Series object \n",
    "display(type(series_age))\n",
    "\n",
    "# I want to get a list of all those age which are > 45\n",
    "series_age[series_age.apply(lambda age: age>45)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54. , 58. , 55. , 66. , 49. , 65. , 46. , 59. , 71. , 47. , 70.5,\n",
       "       54. , 47. , 51. , 55.5, 51. , 61. , 56. , 50. , 58. , 45.5, 51. ,\n",
       "       59. , 54. , 62. , 50. , 52. , 58. , 63. , 65. , 50. , 54. , 61. ,\n",
       "       45.5, 60. , 46. , 51. , 50. , 64. , 52. , 49. , 65. , 50. , 48. ,\n",
       "       47. , 48. , 56. , 50. , 63. , 58. , 55. , 71. , 54. , 54. , 47. ,\n",
       "       50. , 50. , 64. , 62. , 48. , 62. , 53. , 54. , 47. , 60. , 52. ,\n",
       "       47. , 49. , 49. , 61. , 57. , 80. , 51. , 48. , 56. , 58. , 50. ,\n",
       "       47. , 70. , 60. , 60. , 52. , 49. , 48. , 52. , 50. , 48. , 70. ,\n",
       "       48. , 51. , 48. , 57. , 54. , 46. , 49. , 52. , 62. , 74. , 51. ,\n",
       "       48. , 47. , 47. , 56. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_age[series_age.gt(45)].values # better way since it is vectorized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.apply()` allows you to apply a function element-wise to every value. If you pass in a NumPy function that works on an array, it will broadcast the operation to the series.\n",
    "\n",
    "Because the `.apply` method typically operates on each individual value in the series, the function is called once for every value. If you have one million values in a series, it will be called one million times. It breaks out of the fast vectorized code paths we can leverage in pandas and puts us back to using slow Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .where() method\n",
    "The `.where()` method in pandas is used to conditionally replace values in a DataFrame or Series, similar to applying an \"if\" condition. If a condition is met, it keeps the original value; otherwise, it replaces it with a specified alternative.\n",
    "\n",
    "### Syntax\n",
    "```python\n",
    "DataFrame.where(cond, other=NaN, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
    "```\n",
    "\n",
    "- `cond`: Condition to apply (boolean DataFrame/Series).\n",
    "- `other`: Value to replace where the condition is False.\n",
    "- `inplace`: If True, performs the operation in place.\n",
    "- `axis`: Axis along which to perform the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54.0,\n",
       " 58.0,\n",
       " 55.0,\n",
       " 66.0,\n",
       " 49.0,\n",
       " 65.0,\n",
       " 46.0,\n",
       " 59.0,\n",
       " 71.0,\n",
       " 47.0,\n",
       " 70.5,\n",
       " 54.0,\n",
       " 47.0,\n",
       " 51.0,\n",
       " 55.5,\n",
       " 51.0,\n",
       " 61.0,\n",
       " 56.0,\n",
       " 50.0,\n",
       " 58.0,\n",
       " 45.5,\n",
       " 51.0,\n",
       " 59.0,\n",
       " 54.0,\n",
       " 62.0,\n",
       " 50.0,\n",
       " 52.0,\n",
       " 58.0,\n",
       " 63.0,\n",
       " 65.0,\n",
       " 50.0,\n",
       " 54.0,\n",
       " 61.0,\n",
       " 45.5,\n",
       " 60.0,\n",
       " 46.0,\n",
       " 51.0,\n",
       " 50.0,\n",
       " 64.0,\n",
       " 52.0,\n",
       " 49.0,\n",
       " 65.0,\n",
       " 50.0,\n",
       " 48.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 56.0,\n",
       " 50.0,\n",
       " 63.0,\n",
       " 58.0,\n",
       " 55.0,\n",
       " 71.0,\n",
       " 54.0,\n",
       " 54.0,\n",
       " 47.0,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 64.0,\n",
       " 62.0,\n",
       " 48.0,\n",
       " 62.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 47.0,\n",
       " 60.0,\n",
       " 52.0,\n",
       " 47.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 61.0,\n",
       " 57.0,\n",
       " 80.0,\n",
       " 51.0,\n",
       " 48.0,\n",
       " 56.0,\n",
       " 58.0,\n",
       " 50.0,\n",
       " 47.0,\n",
       " 70.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 52.0,\n",
       " 49.0,\n",
       " 48.0,\n",
       " 52.0,\n",
       " 50.0,\n",
       " 48.0,\n",
       " 70.0,\n",
       " 48.0,\n",
       " 51.0,\n",
       " 48.0,\n",
       " 57.0,\n",
       " 54.0,\n",
       " 46.0,\n",
       " 49.0,\n",
       " 52.0,\n",
       " 62.0,\n",
       " 74.0,\n",
       " 51.0,\n",
       " 48.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 56.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = df['Age'].where(df['Age'].gt(45),\n",
    "                         other=0).values\n",
    "filtered_result = list(filter(lambda x:x>0, result))\n",
    "display(filtered_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .where() method is ideal for masking specific values based on complex conditions, retaining more control over data transformations compared to basic indexing or filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0\n",
      "1      38.0\n",
      "2       0.0\n",
      "3      35.0\n",
      "4      35.0\n",
      "       ... \n",
      "886     0.0\n",
      "887     0.0\n",
      "888     0.0\n",
      "889     0.0\n",
      "890    32.0\n",
      "Name: Age, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Replace values in 'A' less than 30 or in 'B' greater than 45 with NaN\n",
    "result = df['Age'].where((df['Age'] >= 30) & (df['Age'] <= 45),\n",
    "                         other=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mask()` function in pandas is similar to `.where()` but works in the opposite way. It replaces values in a DataFrame or Series where a specified condition is False instead of True.\n",
    "\n",
    "```python\n",
    "DataFrame.mask(cond, other=NaN, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
    "```\n",
    "- cond: A condition (boolean DataFrame/Series) specifying where to replace values.\n",
    "- other: The value to replace where the condition is True.\n",
    "- inplace: If True, modifies the data in place.\n",
    "- axis: The axis along which to apply the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.0,\n",
       " 38.0,\n",
       " 26.0,\n",
       " 35.0,\n",
       " 35.0,\n",
       " 2.0,\n",
       " 27.0,\n",
       " 14.0,\n",
       " 4.0,\n",
       " 20.0,\n",
       " 39.0,\n",
       " 14.0,\n",
       " 2.0,\n",
       " 31.0,\n",
       " 35.0,\n",
       " 34.0,\n",
       " 15.0,\n",
       " 28.0,\n",
       " 8.0,\n",
       " 38.0,\n",
       " 19.0,\n",
       " 40.0,\n",
       " 28.0,\n",
       " 42.0,\n",
       " 21.0,\n",
       " 18.0,\n",
       " 14.0,\n",
       " 40.0,\n",
       " 27.0,\n",
       " 3.0,\n",
       " 19.0,\n",
       " 18.0,\n",
       " 7.0,\n",
       " 21.0,\n",
       " 29.0,\n",
       " 21.0,\n",
       " 28.5,\n",
       " 5.0,\n",
       " 11.0,\n",
       " 22.0,\n",
       " 38.0,\n",
       " 45.0,\n",
       " 4.0,\n",
       " 29.0,\n",
       " 19.0,\n",
       " 17.0,\n",
       " 26.0,\n",
       " 32.0,\n",
       " 16.0,\n",
       " 21.0,\n",
       " 26.0,\n",
       " 32.0,\n",
       " 25.0,\n",
       " 0.83,\n",
       " 30.0,\n",
       " 22.0,\n",
       " 29.0,\n",
       " 28.0,\n",
       " 17.0,\n",
       " 33.0,\n",
       " 16.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 29.0,\n",
       " 20.0,\n",
       " 26.0,\n",
       " 23.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 28.0,\n",
       " 21.0,\n",
       " 33.0,\n",
       " 37.0,\n",
       " 28.0,\n",
       " 21.0,\n",
       " 38.0,\n",
       " 14.5,\n",
       " 22.0,\n",
       " 20.0,\n",
       " 17.0,\n",
       " 21.0,\n",
       " 29.0,\n",
       " 24.0,\n",
       " 2.0,\n",
       " 21.0,\n",
       " 32.5,\n",
       " 32.5,\n",
       " 12.0,\n",
       " 24.0,\n",
       " 45.0,\n",
       " 33.0,\n",
       " 20.0,\n",
       " 29.0,\n",
       " 25.0,\n",
       " 23.0,\n",
       " 19.0,\n",
       " 37.0,\n",
       " 16.0,\n",
       " 24.0,\n",
       " 22.0,\n",
       " 24.0,\n",
       " 19.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 27.0,\n",
       " 9.0,\n",
       " 36.5,\n",
       " 42.0,\n",
       " 22.0,\n",
       " 40.5,\n",
       " 16.0,\n",
       " 30.0,\n",
       " 44.0,\n",
       " 40.0,\n",
       " 26.0,\n",
       " 17.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 45.0,\n",
       " 28.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 21.0,\n",
       " 18.0,\n",
       " 30.0,\n",
       " 36.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 45.0,\n",
       " 40.0,\n",
       " 36.0,\n",
       " 32.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 3.0,\n",
       " 44.0,\n",
       " 42.0,\n",
       " 24.0,\n",
       " 28.0,\n",
       " 34.0,\n",
       " 18.0,\n",
       " 2.0,\n",
       " 32.0,\n",
       " 26.0,\n",
       " 16.0,\n",
       " 40.0,\n",
       " 24.0,\n",
       " 35.0,\n",
       " 22.0,\n",
       " 30.0,\n",
       " 31.0,\n",
       " 27.0,\n",
       " 42.0,\n",
       " 32.0,\n",
       " 30.0,\n",
       " 16.0,\n",
       " 27.0,\n",
       " 38.0,\n",
       " 22.0,\n",
       " 19.0,\n",
       " 20.5,\n",
       " 18.0,\n",
       " 35.0,\n",
       " 29.0,\n",
       " 5.0,\n",
       " 24.0,\n",
       " 44.0,\n",
       " 8.0,\n",
       " 19.0,\n",
       " 33.0,\n",
       " 29.0,\n",
       " 22.0,\n",
       " 30.0,\n",
       " 44.0,\n",
       " 25.0,\n",
       " 24.0,\n",
       " 37.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 41.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 35.0,\n",
       " 3.0,\n",
       " 40.0,\n",
       " 36.0,\n",
       " 16.0,\n",
       " 25.0,\n",
       " 35.0,\n",
       " 25.0,\n",
       " 41.0,\n",
       " 37.0,\n",
       " 45.0,\n",
       " 7.0,\n",
       " 35.0,\n",
       " 28.0,\n",
       " 16.0,\n",
       " 19.0,\n",
       " 33.0,\n",
       " 30.0,\n",
       " 22.0,\n",
       " 42.0,\n",
       " 22.0,\n",
       " 26.0,\n",
       " 19.0,\n",
       " 36.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 23.5,\n",
       " 2.0,\n",
       " 19.0,\n",
       " 0.92,\n",
       " 17.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 24.0,\n",
       " 18.0,\n",
       " 26.0,\n",
       " 28.0,\n",
       " 43.0,\n",
       " 26.0,\n",
       " 24.0,\n",
       " 31.0,\n",
       " 40.0,\n",
       " 22.0,\n",
       " 27.0,\n",
       " 30.0,\n",
       " 22.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 31.0,\n",
       " 16.0,\n",
       " 38.0,\n",
       " 16.0,\n",
       " 29.0,\n",
       " 41.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 2.0,\n",
       " 24.0,\n",
       " 28.0,\n",
       " 25.0,\n",
       " 36.0,\n",
       " 24.0,\n",
       " 40.0,\n",
       " 3.0,\n",
       " 42.0,\n",
       " 23.0,\n",
       " 15.0,\n",
       " 25.0,\n",
       " 28.0,\n",
       " 22.0,\n",
       " 38.0,\n",
       " 40.0,\n",
       " 29.0,\n",
       " 45.0,\n",
       " 35.0,\n",
       " 30.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 22.0,\n",
       " 3.0,\n",
       " 22.0,\n",
       " 27.0,\n",
       " 20.0,\n",
       " 19.0,\n",
       " 42.0,\n",
       " 1.0,\n",
       " 32.0,\n",
       " 35.0,\n",
       " 18.0,\n",
       " 1.0,\n",
       " 36.0,\n",
       " 17.0,\n",
       " 36.0,\n",
       " 21.0,\n",
       " 28.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 22.0,\n",
       " 31.0,\n",
       " 23.0,\n",
       " 28.0,\n",
       " 39.0,\n",
       " 26.0,\n",
       " 21.0,\n",
       " 28.0,\n",
       " 20.0,\n",
       " 34.0,\n",
       " 3.0,\n",
       " 21.0,\n",
       " 33.0,\n",
       " 44.0,\n",
       " 34.0,\n",
       " 18.0,\n",
       " 30.0,\n",
       " 10.0,\n",
       " 21.0,\n",
       " 29.0,\n",
       " 28.0,\n",
       " 18.0,\n",
       " 28.0,\n",
       " 19.0,\n",
       " 32.0,\n",
       " 28.0,\n",
       " 42.0,\n",
       " 17.0,\n",
       " 14.0,\n",
       " 21.0,\n",
       " 24.0,\n",
       " 31.0,\n",
       " 45.0,\n",
       " 20.0,\n",
       " 25.0,\n",
       " 28.0,\n",
       " 4.0,\n",
       " 13.0,\n",
       " 34.0,\n",
       " 5.0,\n",
       " 36.0,\n",
       " 30.0,\n",
       " 29.0,\n",
       " 34.0,\n",
       " 38.0,\n",
       " 0.75,\n",
       " 38.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 22.0,\n",
       " 34.0,\n",
       " 29.0,\n",
       " 22.0,\n",
       " 2.0,\n",
       " 9.0,\n",
       " 25.0,\n",
       " 35.0,\n",
       " 30.0,\n",
       " 9.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 25.0,\n",
       " 24.0,\n",
       " 17.0,\n",
       " 21.0,\n",
       " 37.0,\n",
       " 16.0,\n",
       " 18.0,\n",
       " 33.0,\n",
       " 28.0,\n",
       " 26.0,\n",
       " 29.0,\n",
       " 36.0,\n",
       " 24.0,\n",
       " 34.0,\n",
       " 36.0,\n",
       " 32.0,\n",
       " 30.0,\n",
       " 22.0,\n",
       " 44.0,\n",
       " 40.5,\n",
       " 39.0,\n",
       " 23.0,\n",
       " 2.0,\n",
       " 17.0,\n",
       " 30.0,\n",
       " 7.0,\n",
       " 45.0,\n",
       " 30.0,\n",
       " 22.0,\n",
       " 36.0,\n",
       " 9.0,\n",
       " 11.0,\n",
       " 32.0,\n",
       " 19.0,\n",
       " 33.0,\n",
       " 8.0,\n",
       " 17.0,\n",
       " 27.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 39.0,\n",
       " 36.0,\n",
       " 40.0,\n",
       " 28.0,\n",
       " 24.0,\n",
       " 19.0,\n",
       " 29.0,\n",
       " 32.0,\n",
       " 36.0,\n",
       " 16.0,\n",
       " 19.0,\n",
       " 34.0,\n",
       " 39.0,\n",
       " 32.0,\n",
       " 25.0,\n",
       " 39.0,\n",
       " 36.0,\n",
       " 18.0,\n",
       " 22.0,\n",
       " 35.0,\n",
       " 37.0,\n",
       " 36.0,\n",
       " 24.0,\n",
       " 44.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 30.0,\n",
       " 27.0,\n",
       " 22.0,\n",
       " 40.0,\n",
       " 39.0,\n",
       " 35.0,\n",
       " 24.0,\n",
       " 34.0,\n",
       " 26.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 42.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 26.0,\n",
       " 32.0,\n",
       " 9.0,\n",
       " 28.0,\n",
       " 32.0,\n",
       " 31.0,\n",
       " 41.0,\n",
       " 20.0,\n",
       " 24.0,\n",
       " 2.0,\n",
       " 0.75,\n",
       " 19.0,\n",
       " 23.0,\n",
       " 18.0,\n",
       " 21.0,\n",
       " 18.0,\n",
       " 24.0,\n",
       " 32.0,\n",
       " 23.0,\n",
       " 40.0,\n",
       " 36.0,\n",
       " 20.0,\n",
       " 32.0,\n",
       " 25.0,\n",
       " 43.0,\n",
       " 40.0,\n",
       " 31.0,\n",
       " 31.0,\n",
       " 18.0,\n",
       " 24.5,\n",
       " 18.0,\n",
       " 43.0,\n",
       " 36.0,\n",
       " 27.0,\n",
       " 20.0,\n",
       " 14.0,\n",
       " 25.0,\n",
       " 14.0,\n",
       " 19.0,\n",
       " 18.0,\n",
       " 15.0,\n",
       " 31.0,\n",
       " 4.0,\n",
       " 25.0,\n",
       " 44.0,\n",
       " 42.0,\n",
       " 18.0,\n",
       " 35.0,\n",
       " 18.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 39.0,\n",
       " 45.0,\n",
       " 42.0,\n",
       " 22.0,\n",
       " 24.0,\n",
       " 29.0,\n",
       " 19.0,\n",
       " 38.0,\n",
       " 27.0,\n",
       " 33.0,\n",
       " 6.0,\n",
       " 17.0,\n",
       " 34.0,\n",
       " 27.0,\n",
       " 20.0,\n",
       " 30.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 29.0,\n",
       " 11.0,\n",
       " 23.0,\n",
       " 23.0,\n",
       " 28.5,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 21.0,\n",
       " 24.0,\n",
       " 31.0,\n",
       " 16.0,\n",
       " 30.0,\n",
       " 19.0,\n",
       " 31.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 33.0,\n",
       " 23.0,\n",
       " 0.67,\n",
       " 28.0,\n",
       " 18.0,\n",
       " 34.0,\n",
       " 33.0,\n",
       " 41.0,\n",
       " 20.0,\n",
       " 36.0,\n",
       " 16.0,\n",
       " 30.5,\n",
       " 32.0,\n",
       " 24.0,\n",
       " 18.0,\n",
       " 5.0,\n",
       " 43.0,\n",
       " 13.0,\n",
       " 17.0,\n",
       " 29.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 18.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 16.0,\n",
       " 25.0,\n",
       " 39.0,\n",
       " 31.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 34.0,\n",
       " 31.0,\n",
       " 11.0,\n",
       " 0.42,\n",
       " 27.0,\n",
       " 31.0,\n",
       " 39.0,\n",
       " 18.0,\n",
       " 39.0,\n",
       " 33.0,\n",
       " 26.0,\n",
       " 39.0,\n",
       " 35.0,\n",
       " 6.0,\n",
       " 30.5,\n",
       " 23.0,\n",
       " 31.0,\n",
       " 43.0,\n",
       " 10.0,\n",
       " 27.0,\n",
       " 38.0,\n",
       " 27.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 15.0,\n",
       " 0.83,\n",
       " 23.0,\n",
       " 18.0,\n",
       " 39.0,\n",
       " 21.0,\n",
       " 32.0,\n",
       " 20.0,\n",
       " 16.0,\n",
       " 30.0,\n",
       " 34.5,\n",
       " 17.0,\n",
       " 42.0,\n",
       " 35.0,\n",
       " 28.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 16.0,\n",
       " 44.0,\n",
       " 18.0,\n",
       " 45.0,\n",
       " 24.0,\n",
       " 41.0,\n",
       " 21.0,\n",
       " 24.0,\n",
       " 42.0,\n",
       " 27.0,\n",
       " 31.0,\n",
       " 4.0,\n",
       " 26.0,\n",
       " 33.0,\n",
       " 28.0,\n",
       " 15.0,\n",
       " 20.0,\n",
       " 19.0,\n",
       " 25.0,\n",
       " 33.0,\n",
       " 22.0,\n",
       " 28.0,\n",
       " 25.0,\n",
       " 39.0,\n",
       " 27.0,\n",
       " 19.0,\n",
       " 26.0,\n",
       " 32.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = df['Age'].mask(df['Age'].gt(45),\n",
    "                         other=0).values\n",
    "filtered_result = list(filter(lambda x:x>0, result))\n",
    "display(filtered_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to write if-elif-else in Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.  , 38.  , 26.  , 35.  ,   nan, 54.  ,  2.  , 27.  , 14.  ,\n",
       "        4.  , 58.  , 20.  , 39.  , 55.  , 31.  , 34.  , 15.  , 28.  ,\n",
       "        8.  , 19.  , 40.  , 66.  , 42.  , 21.  , 18.  ,  3.  ,  7.  ,\n",
       "       49.  , 29.  , 65.  , 28.5 ,  5.  , 11.  , 45.  , 17.  , 32.  ,\n",
       "       16.  , 25.  ,  0.83, 30.  , 33.  , 23.  , 24.  , 46.  , 59.  ,\n",
       "       71.  , 37.  , 47.  , 14.5 , 70.5 , 32.5 , 12.  ,  9.  , 36.5 ,\n",
       "       51.  , 55.5 , 40.5 , 44.  ,  1.  , 61.  , 56.  , 50.  , 36.  ,\n",
       "       45.5 , 20.5 , 62.  , 41.  , 52.  , 63.  , 23.5 ,  0.92, 43.  ,\n",
       "       60.  , 10.  , 64.  , 13.  , 48.  ,  0.75, 53.  , 57.  , 80.  ,\n",
       "       70.  , 24.5 ,  6.  ,  0.67, 30.5 ,  0.42, 34.5 , 74.  ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if-else in pandas \n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Group Division\n",
    "\n",
    "1. **Child**: 0–12 years\n",
    "2. **Teen**: 13–17 years\n",
    "3. **Young Adult**: 18–35 years\n",
    "4. **Middle-Aged Adult**: 36–55 years\n",
    "5. **Senior Adult**: 56–75 years\n",
    "6. **Elderly**: 76+ years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.select(condlist, choicelist, default=0)\n",
    "df['Age Category'] = pd.Series(\n",
    "    np.select([df['Age'].le(12),\n",
    "               np.logical_and(df['Age'].ge(13), df['Age'].le(17)),\n",
    "               np.logical_and(df['Age'].ge(18), df['Age'].le(35)),\n",
    "               np.logical_and(df['Age'].ge(36), df['Age'].le(55)),\n",
    "               np.logical_and(df['Age'].ge(56), df['Age'].le(75)),\n",
    "               df['Age'].ge(76)\n",
    "    ],\n",
    "              ['Child',\n",
    "               'Teen',\n",
    "               'Young Adult',\n",
    "               'Middle-Aged Adult',\n",
    "               'Senior Adult',\n",
    "               'Elderly'\n",
    "              ],\n",
    "              'Other')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age Category\n",
       "Young Adult          384\n",
       "Other                178\n",
       "Middle-Aged Adult    177\n",
       "Child                 69\n",
       "Teen                  44\n",
       "Senior Adult          38\n",
       "Elderly                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which are the columns having missing data?\n",
    "df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the cabin series \n",
    "df['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many null values are present?\n",
    "df['Cabin'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      S\n",
       "2      S\n",
       "4      S\n",
       "5      Q\n",
       "7      S\n",
       "      ..\n",
       "884    S\n",
       "885    Q\n",
       "886    S\n",
       "888    S\n",
       "890    Q\n",
       "Name: Embarked, Length: 687, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say, we want to find the values of Embarked for the missing values of the cabin\n",
    "\n",
    "df['Embarked'].loc[df['Cabin'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  0,   2,   4,   5,   7,   8,   9,  12,  13,  14,\n",
       "       ...\n",
       "       878, 880, 881, 882, 883, 884, 885, 886, 888, 890],\n",
       "      dtype='int64', length=687)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppose i want to get the index \n",
    "df.index[df['Cabin'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.        , 38.        , 26.        , 35.        , 29.69911765,\n",
       "       54.        ,  2.        , 27.        , 14.        ,  4.        ,\n",
       "       58.        , 20.        , 39.        , 55.        , 31.        ,\n",
       "       34.        , 15.        , 28.        ,  8.        , 19.        ,\n",
       "       40.        , 66.        , 42.        , 21.        , 18.        ,\n",
       "        3.        ,  7.        , 49.        , 29.        , 65.        ,\n",
       "       28.5       ,  5.        , 11.        , 45.        , 17.        ,\n",
       "       32.        , 16.        , 25.        ,  0.83      , 30.        ,\n",
       "       33.        , 23.        , 24.        , 46.        , 59.        ,\n",
       "       71.        , 37.        , 47.        , 14.5       , 70.5       ,\n",
       "       32.5       , 12.        ,  9.        , 36.5       , 51.        ,\n",
       "       55.5       , 40.5       , 44.        ,  1.        , 61.        ,\n",
       "       56.        , 50.        , 36.        , 45.5       , 20.5       ,\n",
       "       62.        , 41.        , 52.        , 63.        , 23.5       ,\n",
       "        0.92      , 43.        , 60.        , 10.        , 64.        ,\n",
       "       13.        , 48.        ,  0.75      , 53.        , 57.        ,\n",
       "       80.        , 70.        , 24.5       ,  6.        ,  0.67      ,\n",
       "       30.5       ,  0.42      , 34.5       , 74.        ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filling in missing data \n",
    "# let us fill the missing dat\n",
    "\n",
    "df['Age'].fillna(df['Age'].agg('mean')).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "Other          687\n",
       "C23 C25 C27      4\n",
       "G6               4\n",
       "B96 B98          4\n",
       "C22 C26          3\n",
       "              ... \n",
       "E34              1\n",
       "C7               1\n",
       "C54              1\n",
       "E36              1\n",
       "C148             1\n",
       "Name: count, Length: 148, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin'].fillna('Other').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers \n",
    "\n",
    "The `clip()` method in pandas is used to limit the values in a DataFrame or Series to within a specified range. This method is useful for capping values at a minimum or maximum threshold, which can help handle outliers or restrict data within a specific range.\n",
    "\n",
    "### Syntax\n",
    "\n",
    "```python\n",
    "DataFrame.clip(lower=None, upper=None, axis=None, inplace=False)\n",
    "```\n",
    "\n",
    "- **lower**: The minimum threshold. Values below this will be set to `lower`.\n",
    "- **upper**: The maximum threshold. Values above this will be set to `upper`.\n",
    "- **axis**: Specifies which axis to apply the clipping to (default is 0).\n",
    "- **inplace**: If `True`, modifies the original data instead of creating a new one.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "1. **Basic Clipping with Lower and Upper Limits**\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "\n",
    "   data = pd.Series([1, 5, 10, 15, 20])\n",
    "   clipped_data = data.clip(lower=5, upper=15)\n",
    "   print(clipped_data)\n",
    "   ```\n",
    "\n",
    "   **Output:**\n",
    "   ```\n",
    "   0     5\n",
    "   1     5\n",
    "   2    10\n",
    "   3    15\n",
    "   4    15\n",
    "   dtype: int64\n",
    "   ```\n",
    "\n",
    "   - In this example, values below `5` are set to `5` (like the value `1`), and values above `15` are set to `15` (like the value `20`).\n",
    "\n",
    "2. **Clipping Only the Upper Limit**\n",
    "\n",
    "   ```python\n",
    "   data = pd.Series([2, 4, 6, 8, 10])\n",
    "   clipped_data = data.clip(upper=6)\n",
    "   print(clipped_data)\n",
    "   ```\n",
    "\n",
    "   **Output:**\n",
    "   ```\n",
    "   0    2\n",
    "   1    4\n",
    "   2    6\n",
    "   3    6\n",
    "   4    6\n",
    "   dtype: int64\n",
    "   ```\n",
    "\n",
    "   - Here, only the `upper` limit is specified. Values above `6` are capped at `6`.\n",
    "\n",
    "3. **Clipping Using Lower and Upper Values with DataFrames**\n",
    "\n",
    "   ```python\n",
    "   df = pd.DataFrame({\n",
    "       'A': [1, 6, 11, 16],\n",
    "       'B': [2, 7, 12, 17]\n",
    "   })\n",
    "   clipped_df = df.clip(lower=5, upper=15)\n",
    "   print(clipped_df)\n",
    "   ```\n",
    "\n",
    "   **Output:**\n",
    "   ```\n",
    "       A   B\n",
    "   0   5   5\n",
    "   1   6   7\n",
    "   2  11  12\n",
    "   3  15  15\n",
    "   ```\n",
    "\n",
    "   - Each value is clipped between `5` and `15`. Values below `5` are replaced with `5`, and values above `15` are replaced with `15`.\n",
    "\n",
    "The `clip()` method is useful in data preprocessing when you need to restrict data values to a specific range, such as setting a maximum cap on outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.        , 38.        , 26.        , 35.        , 29.69911765,\n",
       "       54.        ,  2.        , 27.        , 14.        ,  4.        ,\n",
       "       58.        , 20.        , 39.        , 55.        , 31.        ,\n",
       "       34.        , 15.        , 28.        ,  8.        , 19.        ,\n",
       "       40.        , 66.        , 42.        , 21.        , 18.        ,\n",
       "        3.        ,  7.        , 49.        , 29.        , 65.        ,\n",
       "       28.5       ,  5.        , 11.        , 45.        , 17.        ,\n",
       "       32.        , 16.        , 25.        ,  0.83      , 30.        ,\n",
       "       33.        , 23.        , 24.        , 46.        , 59.        ,\n",
       "       71.        , 37.        , 47.        , 14.5       , 70.5       ,\n",
       "       32.5       , 12.        ,  9.        , 36.5       , 51.        ,\n",
       "       55.5       , 40.5       , 44.        ,  1.        , 61.        ,\n",
       "       56.        , 50.        , 36.        , 45.5       , 20.5       ,\n",
       "       62.        , 41.        , 52.        , 63.        , 23.5       ,\n",
       "        0.92      , 43.        , 60.        , 10.        , 64.        ,\n",
       "       13.        , 48.        ,  0.75      , 53.        , 57.        ,\n",
       "       80.        , 70.        , 24.5       ,  6.        ,  0.67      ,\n",
       "       30.5       ,  0.42      , 34.5       , 74.        ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.        , 35.        , 26.        , 29.69911765, 27.        ,\n",
       "       31.        , 34.        , 28.        , 29.        , 28.5       ,\n",
       "       32.        , 25.        , 30.        , 33.        , 23.        ,\n",
       "       24.        , 32.5       , 23.5       , 24.5       , 30.5       ,\n",
       "       34.5       ])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove outliers from age \n",
    "df[\"Age\"] = df['Age'].fillna(df[\"Age\"].agg('mean'))\n",
    "df['Age'].clip(\n",
    "    lower=df['Age'].quantile(0.25),\n",
    "    upper=df['Age'].quantile(0.75),\n",
    "    inplace=True\n",
    ")\n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting values using sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    556\n",
       "5      90\n",
       "4      88\n",
       "3      67\n",
       "8      56\n",
       "1      44\n",
       "11     34\n",
       "2      23\n",
       "6      23\n",
       "9      22\n",
       "7      14\n",
       "0       5\n",
       "12      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_4 = pd.Series(data=[5,44,23,67,88,90,23,14,56,22,556,34,2])\n",
    "series_4.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "12      2\n",
       "7      14\n",
       "9      22\n",
       "2      23\n",
       "6      23\n",
       "11     34\n",
       "1      44\n",
       "8      56\n",
       "3      67\n",
       "4      88\n",
       "5      90\n",
       "10    556\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_4.sort_values(key=lambda x: -2*(x**2)+20*x+20, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "3    30\n",
       "4    40\n",
       "5    50\n",
       "7    60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "2    20\n",
       "3    30\n",
       "4    40\n",
       "6    50\n",
       "7    60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "3    30\n",
       "4    40\n",
       "5    50\n",
       "7    60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "3    30\n",
       "4    40\n",
       "7    60\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_5 = pd.Series(data=[10,20,20,30,40,50,50,60])\n",
    "display(series_5.drop_duplicates())\n",
    "display(series_5.drop_duplicates(keep='last')) # keeps the last occurence of the duplicated value - note the index \n",
    "display(series_5.drop_duplicates(keep='first'))\n",
    "display(series_5.drop_duplicates(keep=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Data \n",
    "Assigns ranks to elements in the Series. Useful for finding relative positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.5\n",
       "1    4.0\n",
       "2    1.0\n",
       "3    2.5\n",
       "4    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([100, 200, 50, 100, 300])\n",
    "s.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing Values \n",
    "Replaces specific values in the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1    200\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "s.replace({1: 100, 2: 200})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning Values - `pd.cut()`\n",
    "Bins values into discrete intervals you define (manual buckets). Great for categorizing continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile-based Binning - `pd.qcut()`\n",
    "Quantile-based binning. Automatically divides data into equal-sized groups based on distribution (percentiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
